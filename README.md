# GPT-Insights

### ì´ˆê±°ëŒ€ AI íŠ¸ë Œë“œ ì´í•´ ê³¼ì •(0531) - providing the latest insights on popular trends in GPT
-----

### ê³¼ì • ëª©í‘œ: GPTì˜ ì‘ë™ì›ë¦¬ì™€ ì§„í™” ê³¼ì •ì˜ ì´í•´ ë° í–¥í›„ ê³¼ì œ

-----

### 2024ë…„ 5ì›” 31ì¼ ê¸ˆìš”ì¼ 09:00 ğŸ•¤ ~ 13:00 ğŸ•œ

-----
0. [í”„ë¡œê·¸ë¨ì˜ ì§„í™”ê³¼ì •](https://github.com/JSJeong-me/GPT-Insights/blob/main/images/Program-1.png)

   [ìì—°ì–´ì™€ í”„ë¡œê·¸ë¨ì˜ ê²½ê³„](https://github.com/JSJeong-me/GPT-Insights/blob/main/images/Program-2.png)

2. [GPT3.5 GPT4 Reviewì™€ GPT5 ì— ëŒ€í•´ ë¯¸ë¦¬ ì•Œì•„ë³´ê¸°](https://drive.google.com/file/d/18dVgDszcWE5TkBf-arUrZsWS7WIXlbRc/view?usp=sharing)

   - [Base LLM ê³¼ Instruction Tuned LLM ì˜ ì°¨ì´ ì´í•´](https://drive.google.com/file/d/1WDAImH03T-f5wjXb8MXrbwrZOamE_s6Z/view?usp=sharing)
   - [Embedding](https://platform.openai.com/tokenizer)
   - [Reinforcement Learning Human Feedback (RLHF)](https://drive.google.com/file/d/1lUynjlMYPFcxT2NSSh-44V28Vxvx52vN/view?usp=sharing)
   - Prompt ë€?
   - Theory of Mind
   - [RAG(Retrieve Augmented Generation)](https://drive.google.com/file/d/1Bm4cYqmvLNe_bFzm6B3FUgBXaoP5ARbl/view) [ì‹¤ìŠµë¬¸ì„œ](https://github.com/JSJeong-me/Retriever/blob/main/statics/ECOPRO-20230814-9pages.pdf)

     ![RAG](https://github.com/JSJeong-me/ProDiscovery2LLM/assets/54794815/b06f1ae9-cd23-46ab-b734-2c332541adca)

   - [Fine-tuning Model](https://drive.google.com/file/d/1KQ4TgmXeb5-bIY_rXCKPMEdT_YRmnlYf/view?usp=sharing)
     
     1) [í•™ìŠµë°ì´í„° ìƒì„±](https://docs.google.com/spreadsheets/d/1sJ4X03A_DrBCC24zp_sqiQW17qhVoiOQVr5ScEmhfEo/edit#gid=5293024)
     2) [ì‹¤ìŠµ ì˜ˆì œ 1](https://github.com/JSJeong-me/GPT-Finetuning/blob/main/51-LangChain-ChatBot.ipynb)

3. [ì¶”ë¡ (Reasoning)ì´ë€?](https://github.com/JSJeong-me/GPT-Graph/blob/main/Reasoning.md)

   - [Deductive(ì—°ì—­ ì¶”ë¡ ) ê³¼ Inductive reasoning(ê·€ë‚© ì¶”ë¡ )](https://drive.google.com/file/d/122eW8CoR1a-gajicLMRpYaJGa_XOGNje/view?usp=sharing)
   - [Graphë¥¼ í™œìš©í•œ ì¶”ë¡ ](https://neo4j.com/generativeai/)
   - ['Chain of Thought Reasoning'](https://docs.google.com/spreadsheets/d/1EVpv4AAehEdlitsoAdzzXn074SCUl9tGll1B80kCSZw/edit#gid=466944589)
   - ['Chaining Prompts'](https://docs.google.com/spreadsheets/d/1EVpv4AAehEdlitsoAdzzXn074SCUl9tGll1B80kCSZw/edit#gid=466944589)

4. [GPTs í™œìš©](https://chat.openai.com/gpts)

   - [Multimodal](https://drive.google.com/file/d/1yY0ViA4hrq6V8UyMT9ZVQ-ydHzu2AVzY/view?usp=sharing)
   - [ê¸€ì“°ê¸°](https://docs.google.com/spreadsheets/d/1HpKXHq0X0m5rSX-rBfIiyTrVEpbMIzwRZv9ki8JDxYc/edit#gid=12358067)  [Blog Writer](https://chat.openai.com/g/g-PAFR1uSJk-blog-writer)  [Blog Expert](https://chat.openai.com/g/g-PWizFQk8C-blog-expert)
   - [![resistor-2k](https://github.com/JSJeong-me/GPT-Insights/assets/54794815/81f87f77-a1ae-470e-b70b-0a621ab0950a)](https://github.com/JSJeong-me/GPT-Insights/blob/main/images/resistor-2k.png) [ì •ë‹µ](https://jeong5431.tistory.com/entry/%EC%A0%80%ED%95%AD-%EC%83%89%EB%9D%A0-%EC%9D%BD%EB%8A%94-%EB%B0%A9%EB%B2%95)
   - [Cartoonize Me](https://chat.openai.com/g/g-X2Cy0Tv71-cartoonize-me-image-to-cartoon)


5. [Local LLM ì˜ í•„ìš”ì„±ê³¼ êµ¬í˜„ë°©ì•ˆ](https://drive.google.com/file/d/1bGLnr_m0CP7sDhip3cEgjpCmfYa_Injf/view?usp=sharing)

   - [Samsung Galzxy S24](https://github.com/JSJeong-me/GPT-Insights/blob/main/images/galaxy-s24.png) [https://www.youtube.com/watch?v=kHV3zBaWOHE](https://www.youtube.com/watch?v=kHV3zBaWOHE)
   - [Ollama](https://ollama.ai/library?sort=popular)
   - [Web browser ë‚´ì—ì„œ LLM ì‹¤í–‰](https://drive.google.com/file/d/1f0iEYzn7YdUM_aqVWl1VnVYo4DdQebTB/view?usp=sharing)


6. [LangGraphë¥¼ í™œìš©í•œ ìë™í™” ì˜ˆì œ](https://python.langchain.com/docs/langgraph)

   - [Graph Question & Answering](https://github.com/JSJeong-me/GPT-Graph/blob/main/01-Graph-Question.ipynb)
   - [multi-agent-collaboration](https://github.com/JSJeong-me/GPT-Graph/blob/main/22-multi-agent-collaboration.ipynb)
   - [agent_supervisor](https://github.com/JSJeong-me/GPT-Graph/blob/main/30-agent_supervisor.ipynb)

7. [CrewAI](https://github.com/joaomdmoura/crewai?tab=readme-ov-file)   [gpt-newspaper](https://github.com/assafelovic/gpt-newspaper/tree/master)


### References

![attention](https://github.com/JSJeong-me/ProDiscovery2LLM/assets/54794815/200e4d8e-be5c-47fd-b04a-4723d15bd3aa)


[Transformer](https://machinelearningmastery.com/how-to-implement-scaled-dot-product-attention-from-scratch-in-tensorflow-and-keras/)
