{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1ì„¸ëŒ€: ë¬¸ì¥â€§ì½”ë“œ ìë™ì™„ì„± (Firstâ€‘Gen Autocomplete)\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì€ **ê°„ë‹¨í•œ ë¬¸ì¥/ì½”ë“œ ìë™ì™„ì„±** ì˜ˆì œë¥¼ í†µí•´ 1ì„¸ëŒ€ ì—ì´ì „íŠ¸ ì½”ë”©(í”„ë¡¬í”„íŠ¸ â†’ ì—°ì† í…ìŠ¤íŠ¸/ì½”ë“œ ìƒì„±)ì˜ ì‘ë™ ë°©ì‹ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. \n",
        "\n",
        "**êµ¬ì„±**\n",
        "- OpenAI Python SDK ì„¤ì¹˜ & í‚¤ ì„¤ì •\n",
        "- ë¬¸ì¥ ìë™ì™„ì„± í•¨ìˆ˜ `autocomplete_text`\n",
        "- ì½”ë“œ ìë™ì™„ì„± í•¨ìˆ˜ `autocomplete_code`\n",
        "- (ì„ íƒ) ê°„ë‹¨í•œ Gradio UIë¡œ ì‹¤í—˜í•´ë³´ê¸°\n",
        "\n",
        "> Colabì—ì„œ **ëŸ°íƒ€ì„ â†’ ëŸ°íƒ€ì„ ë‹¤ì‹œ ì‹œì‘**ì´ í•„ìš”í•œ ê²½ìš°ê°€ ìˆìŠµë‹ˆë‹¤. ì…€ì„ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰í•˜ì„¸ìš”."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form"
      },
      "source": [
        "#@title 0) ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
        "!pip -q install --upgrade openai tiktoken gradio\n",
        "print('âœ… ì„¤ì¹˜ ì™„ë£Œ')\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form"
      },
      "source": [
        "#@title 1) API í‚¤ ì„¤ì • ë° í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n",
        "import os, getpass\n",
        "from openai import OpenAI\n",
        "\n",
        "if 'OPENAI_API_KEY' not in os.environ or not os.environ['OPENAI_API_KEY']:\n",
        "    os.environ['OPENAI_API_KEY'] = getpass.getpass('ğŸ”‘ Enter your OpenAI API key: ')\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "# ê¸°ë³¸ ëª¨ë¸ì€ ê²½ëŸ‰/ì €ë¹„ìš© ë²”ìš© í…ìŠ¤íŠ¸ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. í•„ìš”ì‹œ ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ëª¨ë¸ë¡œ êµì²´í•˜ì„¸ìš”.\n",
        "MODEL = 'gpt-4o-mini'  # ì˜ˆ: 'gpt-4o', 'gpt-4.1-mini' ë“±ìœ¼ë¡œ ë³€ê²½ ê°€ëŠ¥\n",
        "print('âœ… API ì¤€ë¹„ ì™„ë£Œ, MODEL =', MODEL)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form"
      },
      "source": [
        "#@title 2) ë¬¸ì¥ ìë™ì™„ì„± í•¨ìˆ˜\n",
        "from typing import Optional\n",
        "\n",
        "def autocomplete_text(prefix: str,\n",
        "                      n_tokens: int = 96,\n",
        "                      temperature: float = 0.7,\n",
        "                      system_prompt: Optional[str] = None) -> str:\n",
        "    \"\"\"ì‚¬ìš©ìê°€ ì œê³µí•œ ë¬¸ì¥/ë‹¨ë½ prefixë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì„œ ì‘ì„±í•©ë‹ˆë‹¤.\"\"\"\n",
        "    if system_prompt is None:\n",
        "        system_prompt = (\n",
        "            'You are an autocomplete engine. Continue the user\\'s text naturally '\n",
        "            'without adding meta commentary or lists unless the style requires it.'\n",
        "        )\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": prefix}\n",
        "    ]\n",
        "    resp = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=messages,\n",
        "        max_tokens=n_tokens,\n",
        "        temperature=temperature,\n",
        "    )\n",
        "    return resp.choices[0].message.content.strip()\n",
        "\n",
        "demo_prefix = \"ì–´ì ¯ë°¤ ë‚˜ëŠ” ì˜ˆìƒì¹˜ ëª»í•œ ì´ë©”ì¼ì„ ë°›ì•˜ë‹¤. ë°œì‹ ìëŠ” ì´ë¦„ë„ ë°íˆì§€ ì•Šì€ ì±„ ë‹¨ í•œ ë¬¸ì¥ë§Œ ë‚¨ê²¼ë‹¤:\"\n",
        "print('ì…ë ¥(prefix):\\n', demo_prefix)\n",
        "print('\\n--- ìë™ì™„ì„± ê²°ê³¼ ---\\n')\n",
        "print(autocomplete_text(demo_prefix))\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form"
      },
      "source": [
        "#@title 3) ì½”ë“œ ìë™ì™„ì„± í•¨ìˆ˜ (Python/JS ë“±)\n",
        "LANG_SNIPPET_GUIDE = {\n",
        "    'python': (\n",
        "        'Continue the following Python code. Keep style consistent, avoid extra comments unless helpful.'\n",
        "    ),\n",
        "    'javascript': (\n",
        "        'Continue the following JavaScript code. Keep style consistent, avoid extra comments unless helpful.'\n",
        "    ),\n",
        "    'java': 'Continue the following Java code.',\n",
        "    'cpp': 'Continue the following C++ code.'\n",
        "}\n",
        "\n",
        "def autocomplete_code(language: str,\n",
        "                      code_prefix: str,\n",
        "                      n_tokens: int = 128,\n",
        "                      temperature: float = 0.4) -> str:\n",
        "    \"\"\"ì£¼ì–´ì§„ ì–¸ì–´ì™€ ì½”ë“œ prefixë¥¼ ì´ì–´ì„œ ì‘ì„±í•©ë‹ˆë‹¤.\"\"\"\n",
        "    guide = LANG_SNIPPET_GUIDE.get(language.lower(), 'Continue the following code.')\n",
        "    system_prompt = (\n",
        "        'You are a code autocomplete engine. Continue the code faithfully. '\n",
        "        'Do not wrap in markdown fences unless they are already present.'\n",
        "    )\n",
        "    user_content = f\"Language: {language}\\nInstruction: {guide}\\n\\n{code_prefix}\"\n",
        "    resp = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_content}\n",
        "        ],\n",
        "        max_tokens=n_tokens,\n",
        "        temperature=temperature,\n",
        "    )\n",
        "    return resp.choices[0].message.content\n",
        "\n",
        "# Python ì˜ˆì‹œ prefix\n",
        "py_prefix = (\n",
        "    \"def fibonacci(n: int):\\n\"\n",
        "    \"    \\\"\\\"\\\"Return the n-th Fibonacci number using iterative DP.\\\"\\\"\\\"\\n\"\n",
        "    \"    if n < 0:\\n\"\n",
        "    \"        raise ValueError('n must be >= 0')\\n\"\n",
        "    \"    a, b = 0, 1\\n\"\n",
        "    \"    for _ in range(n):\\n\"\n",
        "    \"        a, b = b, a + b\\n\"\n",
        "    \"    return a\\n\\n\"\n",
        "    \"# ê°„ë‹¨í•œ ë²¤ì¹˜ë§ˆí¬\\n\"\n",
        "    \"if __name__ == '__main__':\\n\"\n",
        "    \"    import time\\n\"\n",
        "    \"    start = time.time()\\n\"\n",
        "    \"    # TODO: ì—¬ëŸ¬ ì…ë ¥ì— ëŒ€í•´ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì¶œë ¥í•´ë³´ì\\n\"\n",
        ")\n",
        "print('--- ì½”ë“œ ìë™ì™„ì„± (Python) ---')\n",
        "print(autocomplete_code('python', py_prefix))\n",
        "\n",
        "# JavaScript ì˜ˆì‹œ prefix\n",
        "js_prefix = (\n",
        "    \"function debounce(fn, delay) {\\n\"\n",
        "    \"  let timer = null;\\n\"\n",
        "    \"  return function(...args) {\\n\"\n",
        "    \"    clearTimeout(timer);\\n\"\n",
        "    \"    timer = setTimeout(() => fn.apply(this, args), delay);\\n\"\n",
        "    \"  };\\n\"\n",
        "    \"}\\n\\n\"\n",
        "    \"// TODO: ì•„ë˜ search í•¨ìˆ˜ë¥¼ debounceë¡œ ê°ì‹¸ì„œ ì…ë ¥ ì´ë²¤íŠ¸ ìµœì í™”\\n\"\n",
        ")\n",
        "print('\\n--- ì½”ë“œ ìë™ì™„ì„± (JavaScript) ---')\n",
        "print(autocomplete_code('javascript', js_prefix))\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) (ì„ íƒ) Gradio ë¯¸ë‹ˆ UI\n",
        "ë¸Œë¼ìš°ì €ì—ì„œ ê°„í¸í•˜ê²Œ ë¬¸ì¥/ì½”ë“œ ìë™ì™„ì„±ì„ ì‹¤í—˜í•  ìˆ˜ ìˆëŠ” ê°„ë‹¨í•œ UIë¥¼ ì œê³µí•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form"
      },
      "source": [
        "#@title 4) Gradio ì•± ì‹¤í–‰ (ì„ íƒ)\n",
        "import gradio as gr\n",
        "\n",
        "def ui_text(prefix, n_tokens, temperature):\n",
        "    return autocomplete_text(prefix, n_tokens=n_tokens, temperature=temperature)\n",
        "\n",
        "def ui_code(language, code_prefix, n_tokens, temperature):\n",
        "    return autocomplete_code(language, code_prefix, n_tokens=n_tokens, temperature=temperature)\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown('# Firstâ€‘Gen Autocomplete Demo')\n",
        "    with gr.Tab('Text Autocomplete'):\n",
        "        prefix = gr.Textbox(label='Text prefix', value='ì˜¤ëŠ˜ ì•„ì¹¨ì— ë‚˜ëŠ” í‰ì†Œë³´ë‹¤ ì¼ì° ëˆˆì„ ë–´ë‹¤. ì°½ë°–ì„ ë³´ë‹ˆ,')\n",
        "        n_tokens = gr.Slider(16, 512, value=96, step=1, label='max_tokens')\n",
        "        temperature = gr.Slider(0.0, 1.5, value=0.7, step=0.1, label='temperature')\n",
        "        out = gr.Textbox(label='Completion', lines=8)\n",
        "        btn = gr.Button('Generate')\n",
        "        btn.click(ui_text, inputs=[prefix, n_tokens, temperature], outputs=[out])\n",
        "    with gr.Tab('Code Autocomplete'):\n",
        "        language = gr.Dropdown(['python','javascript','java','cpp'], value='python', label='Language')\n",
        "        code_prefix = gr.Code(label='Code prefix', value='def add(a, b):\\n    # TODO: implement\\n    ')\n",
        "        n_tokens_c = gr.Slider(16, 512, value=128, step=1, label='max_tokens')\n",
        "        temperature_c = gr.Slider(0.0, 1.5, value=0.4, step=0.1, label='temperature')\n",
        "        out_c = gr.Code(label='Completion')\n",
        "        btn_c = gr.Button('Generate')\n",
        "        btn_c.click(ui_code, inputs=[language, code_prefix, n_tokens_c, temperature_c], outputs=[out_c])\n",
        "\n",
        "demo.launch()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ì°¸ê³ \n",
        "- Colabì—ì„œ **ëŸ°íƒ€ì„ ìœ í˜•**ì€ Python 3(ê¸°ë³¸)ìœ¼ë¡œ ì§„í–‰í•˜ì„¸ìš”. GPUëŠ” í•„ìˆ˜ ì•„ë‹˜.\n",
        "- ë„¤íŠ¸ì›Œí¬/í‚¤ ë¬¸ì œë¡œ ì‹¤íŒ¨í•˜ëŠ” ê²½ìš°, ë‹¤ì‹œ ì‹¤í–‰í•˜ê±°ë‚˜ í‚¤/ëª¨ë¸ëª…ì„ í™•ì¸í•˜ì„¸ìš”.\n",
        "- ìë™ì™„ì„± íŠ¹ì„±ìƒ **ë³´ì•ˆ ë¯¼ê° ì •ë³´**ë¥¼ í¬í•¨í•˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•˜ì„¸ìš”."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "name": "FirstGen_Autocomplete_Colab.ipynb"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}