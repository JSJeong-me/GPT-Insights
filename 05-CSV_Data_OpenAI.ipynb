{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/GPT-Insights/blob/main/05-CSV_Data_OpenAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d792f35b",
      "metadata": {
        "id": "d792f35b"
      },
      "source": [
        "Interacting with a CSV Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "스마트서울 도시데이터 센서(S-DoT) 2분단위 환경정보\n",
        "더보기\n",
        "※  데이터 변환으로 2024년 7월 10일 이후 부터 이용 가능합니다.\n",
        "### 서울시 전역(1100곳)에 설치된 S-DoT 복합 센서를 통해 2분 간격으로 수집되는 기온, 상대습도, 조도, 소음, 진동, 자외선, 풍향, 풍속, 흑구온도, 대기오염물질, 악취 등의 환경정보 데이터입니다.\n",
        "### 서울 열린데이터광장에서는 동일 데이터로 1시간 단위 평균값으로 제공하고 있습니다.\n"
      ],
      "metadata": {
        "id": "sdmA0f9Yrt-U"
      },
      "id": "sdmA0f9Yrt-U"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv openai langchain langchain-core langchain-community langchain_experimental"
      ],
      "metadata": {
        "id": "R3C8sKoityww"
      },
      "id": "R3C8sKoityww",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"OPENAI_API_KEY=sk-\" >> .env\n",
        "!source /content/.env"
      ],
      "metadata": {
        "id": "1M1XRI6kx0Yx"
      },
      "id": "1M1XRI6kx0Yx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "# Access the API key using the variable name defined in the .env file\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "C9Ha98i_x4Yx"
      },
      "id": "C9Ha98i_x4Yx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import sys\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "\n",
        "openai.api_key  = os.environ['OPENAI_API_KEY']"
      ],
      "metadata": {
        "id": "2XvpLkCOppWg"
      },
      "id": "2XvpLkCOppWg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83ac3e59-d0d1-4110-a059-3a55d0d5e15e",
      "metadata": {
        "height": 217,
        "id": "83ac3e59-d0d1-4110-a059-3a55d0d5e15e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "from IPython.display import Markdown, HTML, display\n",
        "from langchain.schema import HumanMessage\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0.0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba9075a3",
      "metadata": {
        "id": "ba9075a3"
      },
      "source": [
        "## Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Excel file\n",
        "file_path = 'wv-corelation.xlsx'\n",
        "\n",
        "# Read the Excel file into a DataFrame\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Display the first few rows of the DataFrame to understand its structure\n",
        "df.head()"
      ],
      "metadata": {
        "id": "7C8tZbYtqx0S"
      },
      "id": "7C8tZbYtqx0S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the 'ds' column to datetime format\n",
        "df['ds'] = pd.to_datetime(df['ds'])\n",
        "\n",
        "# Set the 'ds' column as the index\n",
        "df.set_index('ds', inplace=True)\n",
        "\n",
        "# Resample the data to 1-hour intervals and calculate the mean for each interval\n",
        "df_resampled = df.resample('1H').mean()\n",
        "\n",
        "# Display the first few rows of the resampled DataFrame\n",
        "print(df_resampled.head())\n",
        "df = df_resampled"
      ],
      "metadata": {
        "id": "cAZ7x2AE288v"
      },
      "id": "cAZ7x2AE288v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a6a261ac",
      "metadata": {
        "id": "a6a261ac"
      },
      "source": [
        "## Prepare the Langchain dataframe agent"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
        "\n",
        "# Ensure you have your LLM instance created as `llm`\n",
        "\n",
        "agent = create_pandas_dataframe_agent(llm=llm, df=df, verbose=True, allow_dangerous_code=True)\n",
        "\n",
        "# Now you can invoke the agent with a query\n",
        "response = agent.invoke(\"what are the names of the columns?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "Xah72iaO15Ue"
      },
      "id": "Xah72iaO15Ue",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "7c6dedce",
      "metadata": {
        "id": "7c6dedce"
      },
      "source": [
        "## Design your prompt and ask your question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d005008-bad6-4458-90ec-6372d9ebe61c",
      "metadata": {
        "height": 523,
        "id": "0d005008-bad6-4458-90ec-6372d9ebe61c"
      },
      "outputs": [],
      "source": [
        "CSV_PROMPT_PREFIX = \"\"\"\n",
        "First set the pandas display options to show all the columns,\n",
        "get the column names, then answer the question.\n",
        "\"\"\"\n",
        "\n",
        "CSV_PROMPT_SUFFIX = \"\"\"\n",
        "- **ALWAYS** before giving the Final Answer, try another method.\n",
        "Then reflect on the answers of the two methods you did and ask yourself\n",
        "if it answers correctly the original question.\n",
        "If you are not sure, try another method.\n",
        "- If the methods tried do not give the same result,reflect and\n",
        "try again until you have two methods that have the same result.\n",
        "- If you still cannot arrive to a consistent result, say that\n",
        "you are not sure of the answer.\n",
        "- If you are sure of the correct answer, create a beautiful\n",
        "and thorough response using Markdown.\n",
        "- **DO NOT MAKE UP AN ANSWER OR USE PRIOR KNOWLEDGE,\n",
        "ONLY USE THE RESULTS OF THE CALCULATIONS YOU HAVE DONE**.\n",
        "- **ALWAYS**, as part of your \"Final Answer\", explain how you got\n",
        "to the answer on a section that starts with: \"\\n\\nExplanation:\\n\".\n",
        "In the explanation, mention the column names that you used to get\n",
        "to the final answer.\n",
        "\"\"\"\n",
        "\n",
        "QUESTION = \"Calculate and analyze the correlation of the 'wv' column with the remaining input columns of the 'target variable'.\"\n",
        "\n",
        "\n",
        "agent.invoke(CSV_PROMPT_PREFIX + QUESTION + CSV_PROMPT_SUFFIX)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "QUESTION = \"Calculate and analyze the correlation of the 'wv' column with the remaining input columns of the 'target variable' and draw a heatmap.\"\n",
        "\n",
        "\n",
        "agent.invoke(CSV_PROMPT_PREFIX + QUESTION + CSV_PROMPT_SUFFIX)"
      ],
      "metadata": {
        "id": "-0FYpNwu3v95"
      },
      "id": "-0FYpNwu3v95",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}