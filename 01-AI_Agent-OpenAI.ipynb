{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/GPT-Insights/blob/main/01-AI_Agent-OpenAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2df80339",
      "metadata": {
        "id": "2df80339"
      },
      "source": [
        "# Lesson 1: Your First AI Agent\n",
        "\n",
        "Welcome to Lesson 1.\n",
        "\n",
        "To access the `requirements.txt` file, please go to the `File` menu and select`Open...`.\n",
        "\n",
        "I hope you enjoy this course!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfdcabc1",
      "metadata": {
        "id": "bfdcabc1"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=11_nDjppPKD6TOB3Zb1RpiAMafKmbc_c5'  -O ./.env"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdNeh_OWwJUX",
        "outputId": "23c9ba26-ec4c-493f-fb24-483623a9d7d7"
      },
      "id": "TdNeh_OWwJUX",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-14 21:56:58--  https://docs.google.com/uc?export=download&id=11_nDjppPKD6TOB3Zb1RpiAMafKmbc_c5\n",
            "Resolving docs.google.com (docs.google.com)... 142.251.2.139, 142.251.2.102, 142.251.2.113, ...\n",
            "Connecting to docs.google.com (docs.google.com)|142.251.2.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=11_nDjppPKD6TOB3Zb1RpiAMafKmbc_c5&export=download [following]\n",
            "--2024-06-14 21:56:59--  https://drive.usercontent.google.com/download?id=11_nDjppPKD6TOB3Zb1RpiAMafKmbc_c5&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 142.251.2.132, 2607:f8b0:4023:c0d::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|142.251.2.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 175 [application/octet-stream]\n",
            "Saving to: ‘./.env’\n",
            "\n",
            "./.env              100%[===================>]     175  --.-KB/s    in 0s      \n",
            "\n",
            "2024-06-14 21:57:00 (3.78 MB/s) - ‘./.env’ saved [175/175]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_B8Kxo6wYJA",
        "outputId": "4db2202d-8846-4de2-d2c1-cd2b7ba65ce7"
      },
      "id": "w_B8Kxo6wYJA",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyodbc==5.1.0 (from -r requirements.txt (line 4))\n",
            "  Downloading pyodbc-5.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (334 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m334.7/334.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tabulate==0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (0.9.0)\n",
            "Collecting openai==1.12.0 (from -r requirements.txt (line 6))\n",
            "  Downloading openai-1.12.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain==0.1.6 (from -r requirements.txt (line 7))\n",
            "  Downloading langchain-0.1.6-py3-none-any.whl (811 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.8/811.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-community==0.0.20 (from -r requirements.txt (line 8))\n",
            "  Downloading langchain_community-0.0.20-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core==0.1.23 (from -r requirements.txt (line 9))\n",
            "  Downloading langchain_core-0.1.23-py3-none-any.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-experimental==0.0.49 (from -r requirements.txt (line 10))\n",
            "  Downloading langchain_experimental-0.0.49-py3-none-any.whl (165 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.7/165.7 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-openai==0.0.5 (from -r requirements.txt (line 11))\n",
            "  Downloading langchain_openai-0.0.5-py3-none-any.whl (29 kB)\n",
            "Collecting pandas==2.2.2 (from -r requirements.txt (line 12))\n",
            "  Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv (from -r requirements.txt (line 13))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.12.0->-r requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.12.0->-r requirements.txt (line 6)) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai==1.12.0->-r requirements.txt (line 6))\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.12.0->-r requirements.txt (line 6)) (2.7.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.12.0->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.12.0->-r requirements.txt (line 6)) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai==1.12.0->-r requirements.txt (line 6)) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.6->-r requirements.txt (line 7)) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.6->-r requirements.txt (line 7)) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.6->-r requirements.txt (line 7)) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.6->-r requirements.txt (line 7)) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.1.6->-r requirements.txt (line 7))\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain==0.1.6->-r requirements.txt (line 7))\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.1,>=0.0.83 (from langchain==0.1.6->-r requirements.txt (line 7))\n",
            "  Downloading langsmith-0.0.92-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.6->-r requirements.txt (line 7)) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.6->-r requirements.txt (line 7)) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.6->-r requirements.txt (line 7)) (8.3.0)\n",
            "  Downloading langsmith-0.0.87-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging<24.0,>=23.2 (from langchain-core==0.1.23->-r requirements.txt (line 9))\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken<0.6.0,>=0.5.2 (from langchain-openai==0.0.5->-r requirements.txt (line 11))\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2->-r requirements.txt (line 12)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2->-r requirements.txt (line 12)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2->-r requirements.txt (line 12)) (2024.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.6->-r requirements.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.6->-r requirements.txt (line 7)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.6->-r requirements.txt (line 7)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.6->-r requirements.txt (line 7)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.6->-r requirements.txt (line 7)) (1.9.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.12.0->-r requirements.txt (line 6)) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.12.0->-r requirements.txt (line 6)) (1.2.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.6->-r requirements.txt (line 7))\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.6->-r requirements.txt (line 7))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.12.0->-r requirements.txt (line 6)) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai==1.12.0->-r requirements.txt (line 6))\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.12.0->-r requirements.txt (line 6))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain==0.1.6->-r requirements.txt (line 7))\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.12.0->-r requirements.txt (line 6)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.12.0->-r requirements.txt (line 6)) (2.18.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.2->-r requirements.txt (line 12)) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.6->-r requirements.txt (line 7)) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.6->-r requirements.txt (line 7)) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.6->-r requirements.txt (line 7)) (3.0.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<0.6.0,>=0.5.2->langchain-openai==0.0.5->-r requirements.txt (line 11)) (2024.5.15)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.6->-r requirements.txt (line 7))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, pyodbc, packaging, mypy-extensions, jsonpointer, h11, typing-inspect, tiktoken, pandas, marshmallow, jsonpatch, httpcore, langsmith, httpx, dataclasses-json, openai, langchain-core, langchain-openai, langchain-community, langchain, langchain-experimental\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.1\n",
            "    Uninstalling packaging-24.1:\n",
            "      Successfully uninstalled packaging-24.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.0.3\n",
            "    Uninstalling pandas-2.0.3:\n",
            "      Successfully uninstalled pandas-2.0.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 2.2.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.0.3, but you have pandas 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.1.6 langchain-community-0.0.20 langchain-core-0.1.23 langchain-experimental-0.0.49 langchain-openai-0.0.5 langsmith-0.0.87 marshmallow-3.21.3 mypy-extensions-1.0.0 openai-1.12.0 packaging-23.2 pandas-2.2.2 pyodbc-5.1.0 python-dotenv-1.0.1 tiktoken-0.5.2 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import sys\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "\n",
        "openai.api_key  = os.environ['OPENAI_API_KEY']"
      ],
      "metadata": {
        "id": "lsG3lxZPwRjv"
      },
      "id": "lsG3lxZPwRjv",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e8a67f41-d133-4e91-b54f-80bb3cd9a666",
      "metadata": {
        "height": 64,
        "id": "e8a67f41-d133-4e91-b54f-80bb3cd9a666"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from IPython.display import Markdown, HTML, display"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4c6e550",
      "metadata": {
        "id": "f4c6e550"
      },
      "source": [
        "## Connect to the Azure OpenAI endpoint\n",
        "\n",
        "**Note**: The pre-configured cloud resource grants you access to the Azure OpenAI GPT model. The key and endpoint provided below are intended for teaching purposes only. Your notebook environment is already set up with the necessary keys, which may differ from those used by the instructor during the filming."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56216e12",
      "metadata": {
        "id": "56216e12"
      },
      "source": [
        "```\n",
        "openai_api_version=\"2023-05-15\"\n",
        "azure_deployment=\"gpt-4-1106\"\n",
        "azure_endpoint=\"https://testadri.openai.azure.com\"\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "178321d6",
      "metadata": {
        "id": "178321d6"
      },
      "source": [
        "## 1. Leveraging Langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c5e4be2b",
      "metadata": {
        "height": 149,
        "id": "c5e4be2b"
      },
      "outputs": [],
      "source": [
        "from langchain.schema import HumanMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# model = AzureChatOpenAI(\n",
        "#     openai_api_version=\"2024-04-01-preview\",\n",
        "#     azure_deployment=\"gpt-4-1106\",\n",
        "#     azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
        "# )\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fde1292",
      "metadata": {
        "id": "9fde1292"
      },
      "source": [
        "## 2. Preparing your prompt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"You're a helpful assistant\"),\n",
        "    HumanMessage(content=\"What is the purpose of model regularization?\"),\n",
        "]"
      ],
      "metadata": {
        "id": "H-cp-6cDv-HD"
      },
      "id": "H-cp-6cDv-HD",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d145d0d-30f2-412b-822c-e23ff9bf2bc4",
      "metadata": {
        "height": 98,
        "id": "0d145d0d-30f2-412b-822c-e23ff9bf2bc4"
      },
      "outputs": [],
      "source": [
        "message = HumanMessage(\n",
        "    content=\"Translate this sentence from English \"\n",
        "    \"to French and Spanish. I like red cars and \"\n",
        "    \"blue houses, but my dog is yellow.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94f5e7b6",
      "metadata": {
        "id": "94f5e7b6"
      },
      "source": [
        "## 3. Engaging the model to receive a response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e49e3b6d-71e8-4906-bf9c-fca78c1fbd4c",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e49e3b6d-71e8-4906-bf9c-fca78c1fbd4c",
        "outputId": "0299d1c1-5f2d-4b7e-f2ee-f977dd10210e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"The purpose of model regularization is to prevent overfitting in machine learning models. Overfitting occurs when a model learns the noise and peculiarities in the training data rather than the underlying patterns that generalize well to new, unseen data. Regularization techniques introduce a penalty term to the model's loss function, which helps to control the complexity of the model and reduce overfitting. By adding this penalty, regularization encourages the model to learn simpler patterns that are more likely to generalize to new data, ultimately improving the model's performance on unseen examples.\")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "model.invoke(messages)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}